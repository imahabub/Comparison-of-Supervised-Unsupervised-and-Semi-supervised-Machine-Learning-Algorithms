# -*- coding: utf-8 -*-
"""AB335_Code

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-ryaufLr0zDlrOwPNkO01kCWvNXOlNkS

Importing the required python libraries
"""



import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as plotx
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.linear_model import LogisticRegression
from sklearn.semi_supervised import SelfTrainingClassifier
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

"""Importing the dataset to the dataframe
Showing the first ten rows of the datset
"""

automobile_df= pd.read_csv("/content/imports-85.csv", encoding="latin-1")
automobile_df.head(10)

"""Information regarding the dataset

"""

automobile_df.info()

"""Evaluation of the null values in the dataset"""

automobile_df.isnull().sum()

"""Determination of the duplicate values in the dataset"""

automobile_df.duplicated().any()

"""Removing the null values"""

automobile_df.dropna(inplace=True)

"""Descriptive statistics of the dataset"""

automobile_df.describe()

"""Data Exploration and Visualisation

Distribution of numerical features
"""

numerical_features = ['wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-size', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'Price']
automobile_df[numerical_features].hist(figsize=(15, 10), bins=20, edgecolor='black')
plt.suptitle('Distribution of Numerical Features')
plt.show()

"""Count plot of categorical features"""

categorical_features = ['make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', 'drive-wheels', 'engine-location', 'engine-type', 'num-of-cylinders', 'fuel-system']
for feature in categorical_features:
    plt.figure(figsize=(10, 6))
    sns.countplot(data=automobile_df, x=feature)
    plt.title(f'Count Plot of {feature}')
    plt.xticks(rotation=45)
    plt.show()

"""Pairplot of numerical features"""

sns.pairplot(automobile_df[numerical_features])
plt.suptitle('Pairplot of Numerical Features', y=1.02)
plt.show()

"""Check the types of your numerical features"""

print(automobile_df[numerical_features].dtypes)

"""Look for any non-numeric values"""

for column in numerical_features:
    non_numeric = automobile_df[column].apply(lambda x: not isinstance(x, (int, float)))
    if non_numeric.any():
        print(f"Non-numeric values found in column: {column}")
        print(automobile_df[non_numeric][column].unique())

"""Convert '?' and other non-numeric values to NaN"""

automobile_df.replace('?', np.nan, inplace=True)

"""Convert columns to numeric (forcing errors to NaN)"""

for column in numerical_features:
    automobile_df[column] = pd.to_numeric(automobile_df[column], errors='coerce')

"""Drop rows with missing values in the numerical features"""

automobile_df.dropna(subset=numerical_features, inplace=True)

"""Or, alternatively, fill missing values with the mean (or another value)"""

automobile_df[numerical_features] = automobile_df[numerical_features].fillna(automobile_df[numerical_features].mean())

"""Correlation heatmap"""

correlation_matrix = automobile_df[numerical_features].corr()
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap of Numerical Features')
plt.show()

"""Scatter plot of engine-size vs. horsepower"""

plotx.scatter(automobile_df, x='engine-size', y='horsepower', title='Engine Size vs. Horsepower', labels={'engine-size': 'Engine Size', 'horsepower': 'Horsepower'})
plt.show()

"""Boxplot of city-mpg by body-style"""

plt.figure(figsize=(12, 6))
sns.boxplot(data=automobile_df, x='body-style', y='city-mpg')
plt.title('City MPG by Body Style')
plt.xticks(rotation=45)
plt.show()

"""Data Preprocessing"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder

"""Define features and target"""

features = automobile_df.drop(columns=['make'])
target = automobile_df['make']

"""Separate numerical and categorical features"""

numerical_features = automobile_df.select_dtypes(include=['float64', 'int64']).columns
categorical_features = automobile_df.select_dtypes(include=['object']).columns

"""Numerical features preprocessing"""

numerical_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='mean')),  # Handle missing values
    ('scaler', StandardScaler())  # Feature scaling
])

"""Categorical features preprocessing"""

categorical_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing values
    ('encoder', OneHotEncoder(drop='first', sparse=False))  # One-hot encoding
])

"""Full preprocessing pipeline"""

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_pipeline, numerical_features),
        ('cat', categorical_pipeline, categorical_features)
    ]
)

"""Create transformers for numerical and categorical data"""

numerical_transformer = StandardScaler()
categorical_transformer = OneHotEncoder(handle_unknown='ignore')

"""Create a preprocessor that applies the transformers"""

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_features),
        ('cat', categorical_transformer, categorical_features)
    ]
)

"""Fit and transform the features"""

X = preprocessor.fit_transform(automobile_df)

"""Preprocess features

# Encode target variable (if it's categorical)
"""

le = LabelEncoder()
y = le.fit_transform(target)

"""Split the data into training and testing sets"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# Output the shapes of the training and testing sets

"""

print(f"Training features shape: {X_train.shape}")
print(f"Testing features shape: {X_test.shape}")
print(f"Training target shape: {y_train.shape}")
print(f"Testing target shape: {y_test.shape}")

"""Supervised Machine Learning Model: Random Forest Classifier"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

"""Initialize and train the RandomForestClassifier"""

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

"""Make predictions"""

unique_classes_test = set(y_test)
unique_classes_pred = set(y_pred)

print("Unique classes in y_test:", unique_classes_test)
print("Unique classes in y_pred:", unique_classes_pred)

print("Number of classes in target_names:", len(le.classes_))
print("Classes in target_names:", le.classes_)

from sklearn.metrics import classification_report

"""Ensure the labels parameter includes all classes in y_test and y_pred"""

all_classes = sorted(unique_classes_test.union(unique_classes_pred))
print("All classes:", all_classes)

"""Generate classification report with labels parameter"""

print("Classification Report:")
print(classification_report(y_test, y_pred, labels=all_classes, target_names=le.classes_))

"""Evaluate the model"""

print("Confusion Matrix:")
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print("Supervised Learning: Linear Regression Results")
print("Mean Squared Error (MSE):", mean_squared_error(y_test, y_pred))
print("RÂ² Score:", r2_score(y_test, y_pred))

"""Feature Importance

Unsupervised Machine Learning: K-Means Clustering
"""

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

"""Preprocess features"""

X = preprocessor.fit_transform(automobile_df)

"""Determine optimal number of clusters using the Elbow Method"""

inertia = []
K = range(1, 11)
for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X)
    inertia.append(kmeans.inertia_)

plt.figure(figsize=(10, 6))
plt.plot(K, inertia, 'bo-')
plt.xlabel('Number of Clusters')
plt.ylabel('Inertia')
plt.title('Elbow Method for Optimal k')
plt.show()

"""Based on the elbow plot, choose the optimal number of clusters (k)"""

optimal_k = 4

"""Apply K-Means Clustering"""

kmeans = KMeans(n_clusters=optimal_k, random_state=42)
clusters = kmeans.fit_predict(X)

"""Add cluster labels to the original dataframe"""

features['Cluster'] = clusters

silhouette_avg = silhouette_score(X, clusters)
print(f"Silhouette Score: {silhouette_avg:.3f}")

"""Display cluster centers"""

cluster_centers = kmeans.cluster_centers_
print("Cluster Centers (after scaling):")
print(cluster_centers)

"""Semi supervised Machine Learning: Self-Training Classifier"""

from sklearn.linear_model import LogisticRegression
from sklearn.semi_supervised import SelfTrainingClassifier
from sklearn.metrics import classification_report, confusion_matrix

"""Full preprocessing pipeline"""

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_pipeline, numerical_features),
        ('cat', categorical_pipeline, categorical_features)
    ]
)

"""Preprocess features"""

X = preprocessor.fit_transform(automobile_df)

"""Encode target variable (if it's categorical)"""

le = LabelEncoder()
y = le.fit_transform(target)

"""Introduce unlabeled data by masking some of the target values"""

import numpy as np

rng = np.random.default_rng(seed=42)
unlabeled_mask = rng.choice([True, False], size=y.shape, p=[0.2, 0.8])
y_unlabeled = np.where(unlabeled_mask, -1, y)

"""Split the data into training and testing sets"""

X_train, X_test, y_train, y_test = train_test_split(X, y_unlabeled, test_size=0.2, random_state=42)

"""Initialize the base classifier and SelfTrainingClassifier"""

base_classifier = LogisticRegression(max_iter=1000, random_state=42)
self_training_clf = SelfTrainingClassifier(base_classifier)

"""Train the Self-Training Classifier"""

self_training_clf.fit(X_train, y_train)

"""Make predictions"""

y_pred = self_training_clf.predict(X_test)

unique_classes_test = set(y_test[y_test != -1])  # Exclude -1 for unlabeled data
unique_classes_pred = set(y_pred[y_pred != -1])

all_classes = sorted(unique_classes_test.union(unique_classes_pred))
print("All classes:", all_classes)

print("Classification Report:")
print(classification_report(y_test, y_pred, labels=all_classes, target_names=le.classes_[:len(all_classes)]))

print("Confusion Matrix:")
conf_matrix = confusion_matrix(y_test, y_pred, labels=all_classes)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_[:len(all_classes)], yticklabels=le.classes_[:len(all_classes)])
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()